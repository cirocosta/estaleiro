# estaleiro v0.0.2

Since the post that introduced [`estaleiro`][estaleiro] (see [A container image builder that (sort of) adheres to the metadata standard for OSL][pivotalk-post]), I got some updates to it and surrounding tooling that I used to develop it ([Concourse][concourse] and [`buildkit`][buildkit]), and `estaleiro` itself.

This marks the very second version of `estaleiro` - v0.0.2 -, with the following highlights:

<!-- START doctoc generated TOC please keep comment here to allow auto update -->
<!-- DON'T EDIT THIS SECTION, INSTEAD RE-RUN doctoc TO UPDATE -->


- [out-of-tree package retrieval](#out-of-tree-package-retrieval)
- [non-ubuntu repositories](#non-ubuntu-repositories)
  - [importing gpg keys](#importing-gpg-keys)
  - [supporting HTTPS-based repositories](#supporting-https-based-repositories)
- [improved CI workflow](#improved-ci-workflow)
- [better buildkit graphs](#better-buildkit-graphs)

<!-- END doctoc generated TOC please keep comment here to allow auto update -->


Coming next, I plan to start working on:

- **scratch-based container images**
  - not all images need ubuntu!
- **improving the codebase**
  - it's getting hairy
- **non-root users**
  - it's about time


Below, the "deets" :grin:


[estaleiro]: https://github.com/pivotal/estaleiro
[buildkit]: https://github.com/moby/buildkit
[concourse]: https://concourse-ci.org
[dot]: https://www.graphviz.org/doc/info/lang.html
[pivotalk-post]: https://www.pivotalk.io/t/a-container-image-builder-that-sort-of-adheres-to-the-metadata-standard-for-osl/29655
[docker-image]: https://github.com/concourse/docker-image-resource
[builder-task]: https://github.com/concourse/builder-task
[registry-image]: https://github.com/concourse/registry-image-resource



## out-of-tree package retrieval

Differently from performing a `docker build` on a Dockerfile that installs a bunch of packages into a container image, `estaleiro` performs all of the debian packages and debian repositories interaction completely out of the chain of mutations that lead to the final container image.

For instance, with a definition

```hcl
image "my-final-image" {
  apt {
    package "vim" {}
  }
}
```

visually, that means something like:

![](https://user-images.githubusercontent.com/3574444/62842395-dd3ad680-bc7f-11e9-9a30-dd198a4221ac.png)


*ps.: `blue` represents the mutations as layers that form the final image. `gray` never gets in - it's just transient*

As all of those packages, repositories infos, and keys are just mounted in, in the history of `final_image` there are no `.deb` packages at any point - just the result of their installation.

The benefit of doing it this way compared to in-tree builds is that we guarantee that we don't pollute the package dependency graph for the final image at any time.


## non-ubuntu repositories

Previously, any packages that were not part of the subset of Ubuntu repositories that we picked as default would not be possible to install.

That's because `estaleiro` used to just use the following `/etc/apt/sources.list`:

```
#                | FREE     | NON-FREE
#    ------------+----------+-----------
#      SUPPORTED | main     | restricted
#    -----------------------------------
#    UNSUPPORTED | universe | multiverse
#
deb http://archive.ubuntu.com/ubuntu/ bionic main restricted
deb-src http://archive.ubuntu.com/ubuntu/ bionic main restricted

deb http://archive.ubuntu.com/ubuntu/ bionic-updates main restricted
deb-src http://archive.ubuntu.com/ubuntu/ bionic-updates main restricted

deb http://archive.ubuntu.com/ubuntu/ bionic-security main restricted
deb-src http://archive.ubuntu.com/ubuntu/ bionic-secufity main restricted
```

Moving forward, `estaleiro` now allows you to specify repositories that are not part of such list.

For instance, consider Concourse's `docker-image-resource`, which relies on `docker-ce` coming from Docker's APT repository (and `jq` coming from Ubuntu's `universe` repository):


```hcl
image "concourse/docker-image-resource" {
  base_image {
    name = "ubuntu"
    ref  = "bionic"
  }

  apt {
    repositories = [
      "deb http://archive.ubuntu.com/ubuntu/ bionic universe",
      "deb-src http://archive.ubuntu.com/ubuntu/ bionic universe",
      "deb https://download.docker.com/linux/ubuntu bionic stable",
    ]

    key "docker" {
      uri = "https://download.docker.com/linux/ubuntu/gpg"
    }

    package "ca-certificates" {}
    package "docker-ce" {}
    package "jq" {}
  }
}
```

To achieve that, two things were necessary to be worked on:

1. importing gpg keys to apt's keyring
2. supporting HTTPS-based repositories


### importing gpg keys

This one revealed quite interesting to me as I've never really dug deep into what `apt-key add -` really meant when following installation guides on "the interwebz".

In order to get `apt` to trust a particular repository, it needs to first trust it by having us (the users), adding the public key of the repository that signs the packages that live in such repository.


`ubuntu` ships with a default set of them for the traditional ubuntu repositories (under `/etc/apt/trusted.gpg.d`). Importing new ones means leveraging `gnupg` to add them to a `/etc/apt/trusted.gpg` that represents extra keys that are trusted by the user.


```

    "I trust `download.docker.com`!
        
        ---> fetches `docker`'s public key
        ---> adds to trusted keyring



    "Let me tell `apt` about Docker's debian repository"

        ---> adds `download.docker.com` to `/etc/apt/sources.list`



    "Let me update my local database of where I can fetch packages from so
     that `apt install` knows where to look at"
      
        ---> retrieves packages listing from repositories
             that it trusts



    "Let me install `docker-ce`!"

        ---> retrieves `docker-ce` (+ deps) from docker's repository

```

`estaleiro`'s approach then is not much different - it fetches the public keys you want, adds them to the `keyring`, letting any `apt` operations then know that you trust that domain.


For the purpose of "always knowing what's going on", it takes the opportunity to write down to the bill of materials the fingerprints of the keys.


### supporting HTTPS-based repositories

As certain repositories like `download.docker.com` only serve packages through `https`, that means that while performing the repository info fetching we need to have some CA certificates on our hands.

The usual way to have some certificates then is installing `ca-certificates`, but doing so would mean polluting the final packages graph that `apt` would use to compute whether packages are needed to be fetched or not.

As a way of preventing that pollution, I took the approach of retrieving that `ca-certificates` in the layer where we deal with keys (an out-of-tree layer where some base packages are already there), and then mounting those certificates over to the layer where we need to interact with those HTTPS-based repositories:


![](https://user-images.githubusercontent.com/3574444/62842982-53d9d300-bc84-11e9-8584-91ff20441b57.png)

*ps.: `blue` is "in-tree" (ends up in the final layer chain), `gray` and `boxed` is "out-of-tree" (does not end up in the final layer chain)*



## improved CI workflow

Since at least the beginning of the year, the Concourse team has been pushing the idea of separating the [`docker-image`][docker-image] resource type in two:

- a task that does the container image building ([`builder-task`][builder-task])
- a resource type that deals with checking/fetching/pushing container images from/to registries ([`registry-image-resource`][registry-image])


```yaml
jobs:
- name: job
  plan:
    - get: repository
    - task: build
      privileged: true
      file: repository/ci/build.yml
    - put: container-image
      inputs: [image]
      params: {image: image/image.tar}
```

which then turns into


```


                  (builder)
              .---- task ------.
              |                |         (registry-image-resource)
              |                |             .---- put ----*
  repository -+- ./repository  |             |             |
  (from get)  |  ./image ------+-- image ----+- ./image    |
              |                |             |      |      |
              |                |             *------+------*
              *----------------*                    |
                                                    |
                                                    |
                    container image registry <------*
                  (dockerhub / gcr / docker-registry ... )


```

This has all to do with `estaleiro` because separation means that in order to have someone pushing images that have their bill of materials generated, all that they need to do is swap `builder` there, and let `registry-image-resource` take care of sending the generated container image to the registry configured.

```

                 (estaleiro)
              .---- task ------.
              |                |         (registry-image-resource)
              |                |             .---- put ----*
  repository -+- ./repository  |             |             |
  (from get)  |  ./image ------+-- image ----+- ./image    |
              |                |             |      |      |
              |                |             *------+------*
              *----------------*                    |
                                                    |
                                                    |
                    container image registry <------*
                  (dockerhub / gcr / docker-registry ... )

```

The problem though, is that the artifact that `buildkit` ends up producing under the hood


When I first started setting up some automation for testing `estaleiro`, I had problems with the way that I was exporting the final container images in Concourse, pretty much hitting what the following issue covers:


- https://github.com/concourse/registry-image-resource/issues/49

The `tl;dr` is: what `buildkit` correctly calls "oci" when exporting, doesn't match `concourse/registry-image-resource` version of what "oci" means.

I updated the image exporter that I was using, and now things are working quite well! It's failing where it should!

![](https://user-images.githubusercontent.com/3574444/62843054-f5f9bb00-bc84-11e9-9211-eeda84fd7fcd.png)

ps.: you can see it here: https://hush-house.pivotal.io/teams/main/pipelines/estaleiro



## better buildkit graphs

Previously, when converting the intermediary representation (LLB) that `estaleiro` produces to a [dot-notation][dot] graph, we'd not be able to see operations that involved file manipulation between states (e.g., `copy`ing files).

This made the process of debugging hard as having to rely on the `json` representation was not very pleasant.

I made a PR to fix that:

- https://github.com/moby/buildkit/pull/1110

Now, the graph for building `estaleiro` itself looks like this:


![graph](https://user-images.githubusercontent.com/3574444/62843093-3f4a0a80-bc85-11e9-95ed-7eb0b0587598.png)


---

That's all!

If you have any comments / feedback, **PLEASE** let me know! Either reply here (preferred), or chat with me directly on Slack.

Thanks!

